{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2dFAORFAbRKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dca788d-98e5-412c-ce18-ff28b355ada0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-3.8.1-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-skinny==3.8.1 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.8.1-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.8.1 (from mlflow)\n",
            "  Downloading mlflow_tracing-3.8.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting Flask-CORS<7 (from mlflow)\n",
            "  Downloading flask_cors-6.0.2-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.17.2)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting huey<3,>=2.5.0 (from mlflow)\n",
            "  Downloading huey-2.5.5-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.45)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (6.2.4)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (3.1.2)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.8.1->mlflow)\n",
            "  Downloading databricks_sdk-0.76.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (0.123.10)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (1.37.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (2.12.3)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (1.2.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (0.5.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.8.1->mlflow) (0.38.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.4)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.23)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (2.43.0)\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.8.1->mlflow) (0.50.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.8.1->mlflow) (0.0.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.8.1->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.8.1->mlflow) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.1->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.1->mlflow) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.8.1->mlflow) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.1->mlflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.1->mlflow) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.8.1->mlflow) (2025.11.12)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.8.1->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.8.1->mlflow) (4.12.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow) (0.6.1)\n",
            "Downloading mlflow-3.8.1-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.8.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.8.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-6.0.2-py3-none-any.whl (13 kB)\n",
            "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huey-2.5.5-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.76.0-py3-none-any.whl (774 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.7/774.7 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: huey, gunicorn, graphql-core, graphql-relay, docker, graphene, Flask-CORS, databricks-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
            "Successfully installed Flask-CORS-6.0.2 databricks-sdk-0.76.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.5.5 mlflow-3.8.1 mlflow-skinny-3.8.1 mlflow-tracing-3.8.1\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "!pip install mlflow\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report\n",
        "import os\n",
        "\n",
        "# Ensure models directory exists\n",
        "os.makedirs(\"../models\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load & Split Data\n",
        "data_path = \"/content/sample_data/data/raw/heart.csv\"\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Convert target if not already done in raw file\n",
        "if 'target' not in df.columns:\n",
        "    df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
        "    df = df.drop(columns=['num'])\n",
        "\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# 80-20 Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"Training Shape: {X_train.shape}\")\n",
        "print(f\"Testing Shape: {X_test.shape}\")"
      ],
      "metadata": {
        "id": "k3-_lVXDbYfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc9caa3f-42b7-4e76-81c0-a6f0f49ad76d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Shape: (242, 13)\n",
            "Testing Shape: (61, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Preprocessing Pipeline\n",
        "# This must match exactly what we will use in production/inference\n",
        "\n",
        "# Identify column types\n",
        "numeric_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "categorical_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
        "\n",
        "# 1. Numeric: Impute missing (median) -> Scale (StandardScaler)\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# 2. Categorical: Impute missing (mode) -> OneHot Encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "print(\"Pipeline constructed successfully.\")"
      ],
      "metadata": {
        "id": "G4889WE4bdDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb2cc92-4bb0-49cd-c724-2dc86d934489"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline constructed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLflow Setup\n",
        "# Set the experiment name\n",
        "mlflow.set_experiment(\"Heart_Disease_Experiments\")\n",
        "\n",
        "def eval_metrics(actual, pred, probs):\n",
        "    accuracy = accuracy_score(actual, pred)\n",
        "    precision = precision_score(actual, pred)\n",
        "    recall = recall_score(actual, pred)\n",
        "    roc_auc = roc_auc_score(actual, probs)\n",
        "    return accuracy, precision, recall, roc_auc"
      ],
      "metadata": {
        "id": "RqbEdpIrbjeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee2b68b3-7705-45ae-998c-5ce2d793ff23"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026/01/05 10:38:35 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
            "2026/01/05 10:38:35 INFO mlflow.store.db.utils: Updating database tables\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Running upgrade  -> 451aebb31d03, add metric step\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
            "2026/01/05 10:38:35 INFO alembic.runtime.migration: Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 770bee3ae1dd -> a1b2c3d4e5f6, add spans table\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade a1b2c3d4e5f6 -> de4033877273, create entity_associations table\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade de4033877273 -> 1a0cddfcaa16, Add webhooks and webhook_events tables\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 1a0cddfcaa16 -> 534353b11cbc, add scorer tables\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 534353b11cbc -> 71994744cf8e, add evaluation datasets\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 71994744cf8e -> 3da73c924c2f, add outputs to dataset record\n",
            "2026/01/05 10:38:36 INFO alembic.runtime.migration: Running upgrade 3da73c924c2f -> bf29a5ff90ea, add jobs table\n",
            "2026/01/05 10:38:37 INFO alembic.runtime.migration: Running upgrade bf29a5ff90ea -> 1bd49d398cd23, add secrets tables\n",
            "2026/01/05 10:38:37 INFO alembic.runtime.migration: Context impl SQLiteImpl.\n",
            "2026/01/05 10:38:37 INFO alembic.runtime.migration: Will assume non-transactional DDL.\n",
            "2026/01/05 10:38:37 INFO mlflow.tracking.fluent: Experiment with name 'Heart_Disease_Experiments' does not exist. Creating a new experiment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1 - Logistic Regression\n",
        "with mlflow.start_run(run_name=\"Logistic_Regression_Baseline\"):\n",
        "    # Define Model\n",
        "    lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "    # Create Full Pipeline\n",
        "    model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                     ('classifier', lr)])\n",
        "\n",
        "    # Train\n",
        "    model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model_pipeline.predict(X_test)\n",
        "    y_probs = model_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Evaluate\n",
        "    acc, prec, rec, auc = eval_metrics(y_test, y_pred, y_probs)\n",
        "\n",
        "    # Log Parameters & Metrics\n",
        "    mlflow.log_param(\"model_type\", \"LogisticRegression\")\n",
        "    mlflow.log_metric(\"accuracy\", acc)\n",
        "    mlflow.log_metric(\"precision\", prec)\n",
        "    mlflow.log_metric(\"recall\", rec)\n",
        "    mlflow.log_metric(\"roc_auc\", auc)\n",
        "\n",
        "    # Log Model Artifact\n",
        "    mlflow.sklearn.log_model(model_pipeline, \"model\")\n",
        "\n",
        "    print(f\"Logistic Regression - Accuracy: {acc:.4f}, AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "id": "CWy87OCAbn20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ab4dbf-34cc-4721-f9c5-9cae1a9d382c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026/01/05 10:38:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Accuracy: 0.8689, AUC: 0.9102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2 - Random Forest\n",
        "with mlflow.start_run(run_name=\"Random_Forest_Default\"):\n",
        "    # Define Model\n",
        "    rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "\n",
        "    # Create Full Pipeline\n",
        "    rf_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                  ('classifier', rf)])\n",
        "\n",
        "    # Train\n",
        "    rf_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = rf_pipeline.predict(X_test)\n",
        "    y_probs = rf_pipeline.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Evaluate\n",
        "    acc, prec, rec, auc = eval_metrics(y_test, y_pred, y_probs)\n",
        "\n",
        "    # Log Parameters & Metrics\n",
        "    mlflow.log_param(\"model_type\", \"RandomForest\")\n",
        "    mlflow.log_param(\"n_estimators\", 100)\n",
        "    mlflow.log_param(\"max_depth\", 10)\n",
        "    mlflow.log_metric(\"accuracy\", acc)\n",
        "    mlflow.log_metric(\"precision\", prec)\n",
        "    mlflow.log_metric(\"recall\", rec)\n",
        "    mlflow.log_metric(\"roc_auc\", auc)\n",
        "\n",
        "    # Log Model Artifact\n",
        "    mlflow.sklearn.log_model(rf_pipeline, \"model\")\n",
        "\n",
        "    print(f\"Random Forest - Accuracy: {acc:.4f}, AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "id": "m4ycncoIbtIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36bf91f4-ecba-408e-e389-9802cc2dc824"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2026/01/05 10:39:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Accuracy: 0.7869, AUC: 0.9042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Selection & Saving\n",
        "# Assuming Random Forest performed better (check output above)\n",
        "# We save the Random Forest pipeline as our \"Production\" model\n",
        "\n",
        "joblib.dump(rf_pipeline, \"../models/model.joblib\")\n",
        "print(\"Best model saved to ../models/model.joblib\")\n",
        "\n",
        "# Sanity Check: Load and Predict\n",
        "loaded_model = joblib.load(\"../models/model.joblib\")\n",
        "sample_pred = loaded_model.predict(X_test.iloc[:5])\n",
        "print(\"Prediction on first 5 test samples:\", sample_pred)"
      ],
      "metadata": {
        "id": "lnKcVniAbxSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7094cb53-2427-467a-8601-a97a475636f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved to ../models/model.joblib\n",
            "Prediction on first 5 test samples: [0 0 0 1 1]\n"
          ]
        }
      ]
    }
  ]
}